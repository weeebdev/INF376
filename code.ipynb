{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHnblO5koN2c"
      },
      "source": [
        "## Easy\r\n",
        "\r\n",
        "Load Vectors from Gensim, and write cosine distance function that will and find top 100 nearest words for :\r\n",
        "\r\n",
        "```\r\n",
        "apple, queen, ignorance, possibility\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ju9Nkvynk_x"
      },
      "source": [
        "import gensim.downloader as api\r\n",
        "import numpy as np\r\n",
        "import collections"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BlP1bOEnx5f"
      },
      "source": [
        "w2v = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDvQ6WcMn_pB",
        "outputId": "56927c02-9481-4b2f-873a-acc4a29279fa"
      },
      "source": [
        "len(w2v.vocab)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpY89abCoTHv"
      },
      "source": [
        "words = ['apple', 'queen', 'ignorance', 'possibility']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydN4KOKoovHf"
      },
      "source": [
        "for i in words:\r\n",
        "  if i not in w2v:\r\n",
        "    print(f\"Word {i} not in w2v\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfchSWevpHou"
      },
      "source": [
        "def cosSim(word, num=100):\r\n",
        "  res = {}\r\n",
        "  for i in w2v.vocab:\r\n",
        "    res[i] = 1 - np.dot(w2v[word],w2v[i]) \\\r\n",
        "     / \\\r\n",
        "     ( \\\r\n",
        "         np.sqrt(np.dot(w2v[word],w2v[word])) * np.sqrt(np.dot(w2v[i],w2v[i])) \\\r\n",
        "      )\r\n",
        "  return collections.OrderedDict(sorted(res.items(), key=lambda item: item[1])[1:1+num])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Sy_Tst2aB1",
        "outputId": "cbfb625d-caec-4a9a-fbbc-23b908d10752"
      },
      "source": [
        "for i in words:\r\n",
        "  print(f\"Similarities for {i} are:\\n{cosSim(i, 2)}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarities for apple are:\n",
            "OrderedDict([('blackberry', 0.24569332599639893), ('chips', 0.25613564252853394)])\n",
            "Similarities for queen are:\n",
            "OrderedDict([('princess', 0.14848339557647705), ('lady', 0.1949390172958374)])\n",
            "Similarities for ignorance are:\n",
            "OrderedDict([('injustice', 0.17221593856811523), ('selfishness', 0.1891566514968872)])\n",
            "Similarities for possibility are:\n",
            "OrderedDict([('possible', 0.06444436311721802), ('whether', 0.10292595624923706)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ19KbLY22aV"
      },
      "source": [
        "## Medium\r\n",
        "\r\n",
        "Load IMDB dataset, tokenize texts, and display its representation for each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nit6rItr2495"
      },
      "source": [
        "import pandas as pd\r\n",
        "import re"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXhozAHuETk7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnywj9xuEYC8",
        "outputId": "4f2f6160-356a-4e3b-a212-86f5ddb0d168"
      },
      "source": [
        "df = pd.read_csv('./sample_data/IMDB Dataset.csv',error_bad_lines=False, engine=\"python\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping line 2419: unexpected end of data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahqzNV9YFyTi"
      },
      "source": [
        "df['tokens'] = df['review'].apply(lambda doc: list(filter(None,re.split(r'[^\\w]', doc))))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHGbEwfeF7_e",
        "outputId": "7ce31ded-243d-4d96-9a4e-ae1fcadc8cbf"
      },
      "source": [
        "df['w2v'] = df['tokens'].apply(lambda tokens: [w2v[i.lower()] for i in tokens if i.lower() in w2v])\r\n",
        "df['w2v'].head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [[0.31474, 0.41662, 0.1348, 0.15854, 0.88812, ...\n",
              "1    [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...\n",
              "2    [[0.11891, 0.15255, -0.082073, -0.74144, 0.759...\n",
              "3    [[-0.11901, -0.72028, 0.067149, -0.44532, 0.62...\n",
              "4    [[-0.11497, -0.81098, 0.32244, -0.0046624, 0.4...\n",
              "Name: w2v, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jd2GstcBKgx"
      },
      "source": [
        "## Hard\r\n",
        "\r\n",
        "Finish medium task\r\n",
        "For each document find its vector form, by taking a mean of word vectors of each vector. \r\n",
        "\r\n",
        "Use logistic regression to classify messages where input is mean of word2vec vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7gN_8b5H_xt",
        "outputId": "4fc3509c-05c9-4b41-81e7-ca0cdbfe7b18"
      },
      "source": [
        "df['mean'] = df['w2v'].apply(lambda x: np.mean(x, axis=0))\r\n",
        "df['mean'].head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0.23563969, 0.12975053, -0.07267406, -0.17217...\n",
              "1    [0.22607522, 0.20523989, -0.23802738, -0.11300...\n",
              "2    [0.27521876, 0.1606651, -0.13258399, -0.169513...\n",
              "3    [0.25059623, 0.13714078, -0.08698385, -0.15979...\n",
              "4    [0.37243506, 0.24857606, -0.13379185, -0.04750...\n",
              "Name: mean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap3V-qDhOlHN"
      },
      "source": [
        "def posneg(x):\r\n",
        "    if x==\"negative\":\r\n",
        "        return 0\r\n",
        "    elif x==\"positive\":\r\n",
        "        return 1\r\n",
        "    return x\r\n",
        "\r\n",
        "filtered_score = df[\"sentiment\"].map(posneg)\r\n",
        "df[\"score\"] = filtered_score\r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmf2zvIuOMXZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[\"mean\"], df[\"score\"], test_size=0.2)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOXNh89OpJY",
        "outputId": "3580fad8-008a-42ce-af1f-462db49609f1"
      },
      "source": [
        "logReg = LogisticRegression(fit_intercept=True, n_jobs=-1)\r\n",
        "logReg.fit(list(X_train), y_train)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xtcpjC1O3XQ"
      },
      "source": [
        "y_pred_test = logReg.predict(list(X_test))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsOjq9zYPKuV",
        "outputId": "bb38b835-0da4-4c9c-8371-bd36f0207ef7"
      },
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"F1: {f1_score(y_test, y_pred_test)}\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7169421487603306\n",
            "Precision: 0.7489361702127659\n",
            "Recall: 0.6929133858267716\n",
            "F1: 0.719836400817996\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}