{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_youvGMuNFav"
      },
      "source": [
        "## Easy\r\n",
        "\r\n",
        "Use any BBC news article. Analyze it with Name entity recognizer of Spacy, generate Markdown or HTML file, with link of named entity to specified Wikipedia page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNB-vbOLNKaz"
      },
      "source": [
        "import spacy, requests, re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwc_BTMIPUYE"
      },
      "source": [
        "filename = \"./sample_data/text.txt\"\r\n",
        "text = \"  \".join(open(filename).readlines())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9wuUN8U6T5"
      },
      "source": [
        "def getWiki(text):\r\n",
        "  text = re.sub(r'[^\\w]', ' ', text)\r\n",
        "  return requests.get(f'https://en.wikipedia.org/w/api.php?action=opensearch&search={text}&limit=1&namespace=0&format=json').json()[3]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zG53BeAN18l",
        "outputId": "e1b96426-e6ec-4054-9714-cc77ddc8f3d8"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\r\n",
        "doc = nlp(text)\r\n",
        "res = text\r\n",
        "for i in sorted(set([i.text for i in doc.ents]), key=lambda x: len(x), reverse=True):\r\n",
        "    link = getWiki(i)\r\n",
        "    if len(link):\r\n",
        "      rtext = f'[{i}]({link[0]})'\r\n",
        "      res = re.sub(f'(?<![\\[\\(\\/]){i}(?![\\]\\)])', rtext, res)\r\n",
        "print(res)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ely](https://en.wikipedia.org/wiki/Ely), akin to “spoiled”, or “Mama’s boy”.\n",
            "  \n",
            "  But with burgers’ illustrious rise to fame, a homegrown bun-kebab’s identity emerged almost in antithesis. The bun-kebab is what the burger is not: rooted in, not removed from, reality; and owned rather than mocked. As [one](https://en.wikipedia.org/wiki/One) [Pakistani](https://en.wikipedia.org/wiki/Pakistani) wrote in an article in [The Express Tribune](https://en.wikipedia.org/wiki/The_Express_Tribune), “Dear burgers, I am a bun kebab, and proud of it.”\n",
            "  \n",
            "  Dear burgers, I am a bun kebab, and proud of it\n",
            "  \n",
            "  However, with time, it seems that the distinction, especially at a linguistic level, is becoming increasingly blurred. As another [Pakistani](https://en.wikipedia.org/wiki/Pakistani) put it, placing a nation’s identity [between two](https://en.wikipedia.org/wiki/Between_Two_Ferns_with_Zach_Galifianakis) slices of bread is a baffling predicament, especially when the terms start being used interchangeably for the food itself. Colloquial slang surrounding the street food fuels the debate. For example, the practice of referring to bun-kebabs – the food – with the tacked on “waala” (Urdu for the [one](https://en.wikipedia.org/wiki/One)/the [one](https://en.wikipedia.org/wiki/One) with) implies both familiarity and mystery. “There’s this underlying assumption that you don’t exactly know what goes into the bun-kebab. And that’s the beauty of it,” said [Rashid](https://en.wikipedia.org/wiki/Rashid).\n",
            "  \n",
            "  A chicken or beef burger is simply “chicken” or “beef”, whereas “anday-waala”, “daal-waala” or “aloo-waala” bun-kebab (the [one](https://en.wikipedia.org/wiki/One) with eggs, lentils or potatoes respectively) are the customary orders people place, often with a knowing smile. When [Pakistanis](https://en.wikipedia.org/wiki/Pakistanis) ask for “the bun-kebab with...”, they’re asking for more than a snack. They’re asking for an experience – [Pakistani](https://en.wikipedia.org/wiki/Pakistani)-waala.\n",
            "  \n",
            "  In their oily paper packaging, bun-kebabs might get squished. They defy mass-production and don’t offer slick fodder for pretty food-porn.\n",
            "  \n",
            "  But bun-kebabs are unpretentious. They’re home.\n",
            "  \n",
            "  Join more than three million BBC Travel fans by liking us on [Facebook](https://en.wikipedia.org/wiki/Facebook), or follow us on [Twitter](https://en.wikipedia.org/wiki/Twitter) and Instagram.\n",
            "  \n",
            "  If you liked this story, sign up for the [weekly](https://en.wikipedia.org/wiki/Weekly) bbc.com features newsletter called \"The Essential List\". A handpicked selection of stories from [BBC Future](https://en.wikipedia.org/wiki/BBC_Future), Culture, Worklife and Travel, delivered to your inbox every [Friday](https://en.wikipedia.org/wiki/Friday).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4W1gRZ0QS56"
      },
      "source": [
        "f = open(\"res.md\", \"a\")\r\n",
        "f.write(res)\r\n",
        "f.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn2jIMU7NCw5"
      },
      "source": [
        "## Medium\r\n",
        "\r\n",
        "6th Hard task, use Gensim's FastText word vector and compare it with result of 6th Hard Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Vm_GN4NHWZ"
      },
      "source": [
        "import gensim.downloader as api\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Uy-SW_iZcm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIAFMWGgfnpv"
      },
      "source": [
        "w2v = api.load(\"fasttext-wiki-news-subwords-300\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvN0-g5_fuhX"
      },
      "source": [
        "df = pd.read_csv('./sample_data/IMDB Dataset.csv',error_bad_lines=False, engine=\"python\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEDE9DC1ifUX"
      },
      "source": [
        "df['tokens'] = df['review'].apply(lambda doc: list(filter(None,re.split(r'[^\\w]', doc))))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJG9zvhXiitX",
        "outputId": "7837c3cb-7748-4a7b-e9f2-9e13c506f51b"
      },
      "source": [
        "df['w2v'] = df['tokens'].apply(lambda tokens: [w2v[i.lower()] for i in tokens if i.lower() in w2v])\r\n",
        "df['w2v'].head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [[0.019569, 0.0051348, 0.024567, -0.0037714, -...\n",
              "1    [[-0.0079206, -0.095293, 0.031266, 0.017734, -...\n",
              "2    [[-0.060418, 0.069955, 0.053173, 0.052922, 0.0...\n",
              "3    [[0.037373, 0.030506, -0.0062058, 0.011153, 0....\n",
              "4    [[-0.0105, -0.0053143, 0.0080346, 0.00036603, ...\n",
              "Name: w2v, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uLwRAeuiseT",
        "outputId": "4de396af-1222-4740-f80b-2ba924448336"
      },
      "source": [
        "df['mean'] = df['w2v'].apply(lambda x: np.mean(x, axis=0))\r\n",
        "df['mean'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0.0028416538, 0.002920228, 0.022609876, 0.010...\n",
              "1    [0.0062881964, -0.0074260477, 0.031216867, 0.0...\n",
              "2    [-0.00534748, -0.0035081736, 0.024448004, 0.01...\n",
              "3    [0.008908586, -0.0065263174, 0.02462708, 0.018...\n",
              "4    [0.015048433, -0.0055712895, 0.029336138, 0.01...\n",
              "Name: mean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eotOrOSKivRN"
      },
      "source": [
        "def posneg(x):\r\n",
        "    if x==\"negative\":\r\n",
        "        return 0\r\n",
        "    elif x==\"positive\":\r\n",
        "        return 1\r\n",
        "    return x\r\n",
        "\r\n",
        "filtered_score = df[\"sentiment\"].map(posneg)\r\n",
        "df[\"score\"] = filtered_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv9o8H6miv7D"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[\"mean\"], df[\"score\"], test_size=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNr4ZlFviysx",
        "outputId": "6711da55-4b59-4ff9-beaf-b6a222879cbb"
      },
      "source": [
        "logReg = LogisticRegression(fit_intercept=True, n_jobs=-1)\r\n",
        "logReg.fit(list(X_train), y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YmvD-Kii06Z"
      },
      "source": [
        "y_pred_test = logReg.predict(list(X_test))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq3oo_uDi1m6",
        "outputId": "62136ddc-7e35-4169-da6c-0023bcb04bae"
      },
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_test)}\")\r\n",
        "print(f\"F1: {f1_score(y_test, y_pred_test)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8068\n",
            "Precision: 0.7995217218015146\n",
            "Recall: 0.8124746861077359\n",
            "F1: 0.805946163117718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6kTjItHmVZg"
      },
      "source": [
        "Compared to the previous results:  \r\n",
        "Accuracy: 0.7169421487603306  \r\n",
        "Precision: 0.7489361702127659  \r\n",
        "Recall: 0.6929133858267716  \r\n",
        "F1: 0.719836400817996  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ve-qIrwNJzb"
      },
      "source": [
        "## Hard\r\n",
        "\r\n",
        "Solve the following problem, and use Logistic regression or neural network to predict Named entities\r\n",
        "\r\n",
        "[https://www.kaggle.com/abhinavwalia95/entity-annotated-corpushttps://www.kaggle.com/abhinavwalia95/entity-annotated-corpus](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSjVQtPGNNqo"
      },
      "source": [
        "import zipfile\r\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-jgO2Gyndv_"
      },
      "source": [
        "filename = './sample_data/archive.zip'\r\n",
        "zip = zipfile.ZipFile(filename, 'r')\r\n",
        "files = zip.namelist()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4bKI_I0mnn8M",
        "outputId": "3fa10ae1-1a0b-4496-fcf2-bdb7da321c8d"
      },
      "source": [
        "df = pd.read_csv(zip.open(files[1]),encoding='latin1',error_bad_lines=False, engine=\"python\")\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLEjqA1argB_",
        "outputId": "20c71433-027e-4bd4-b415-a97c0b821f56"
      },
      "source": [
        "df['w2v'] = df['Word'].apply(lambda x: w2v[x.lower()] if x.lower() in w2v else np.zeros(w2v.vector_size))\r\n",
        "df = df.iloc[:400000, :]\r\n",
        "df['w2v'].head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [-0.0051715, -0.011219, 0.062319, 0.016572, -0...\n",
              "1    [0.0068832, -0.063845, 0.080359, 0.026035, -0....\n",
              "2    [0.022512, 0.018823, 0.0058266, 0.0051777, -0....\n",
              "3    [-0.016487, -0.058297, 0.0095203, -0.0012367, ...\n",
              "4    [-0.012286, 0.059406, 0.011795, 0.075737, 0.06...\n",
              "Name: w2v, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5tQv3Ms2G7",
        "outputId": "e7b96126-1441-4e98-c67f-a844c468417c"
      },
      "source": [
        "df['w2v'].values.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuISk2ZUtIUr",
        "outputId": "377f32d0-6923-4413-e037-0d3534d3a302"
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')\r\n",
        "pos = enc.fit_transform(df[[\"POS\"]]).toarray()\r\n",
        "print(pos.shape)\r\n",
        "print(np.vstack(df['w2v'].values).shape)\r\n",
        "X = np.concatenate((np.vstack(df['w2v'].values), pos), axis=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400000, 41)\n",
            "(400000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzXhC9W1eLn"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, df[\"Tag\"], test_size=0.2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhG8cHgE20Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bc3048-da19-4f3e-c809-dd7f96a86927"
      },
      "source": [
        "logReg = LogisticRegression(fit_intercept=True, n_jobs=-1)\r\n",
        "logReg.fit(list(X_train), y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBxYbZyy23VY"
      },
      "source": [
        "y_pred_test = logReg.predict(list(X_test))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9fk9Fbe24kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3a6749-daec-4bba-a160-605421c4a74c"
      },
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\r\n",
        "# print(f\"Precision: {precision_score(y_test, y_pred_test)}\")\r\n",
        "# print(f\"Recall: {recall_score(y_test, y_pred_test)}\")\r\n",
        "# print(f\"F1: {f1_score(y_test, y_pred_test)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.94315\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}